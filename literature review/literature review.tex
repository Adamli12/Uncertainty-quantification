\documentclass{ctexart}
\usepackage[colorlinks,linkcolor=red, anchorcolor=blue, citecolor=green]{hyperref}
\title{Uncertainty Quantification in deep learning: Literature Review and Taxonomy}
\author{Hanyu Li}

\begin{document}
\maketitle
\section{epistemic uncertainty}

\subsection{definition}
Epistemic uncertainty accounts for uncertainty in the model parameters â€“ uncertainty which captures our ignorance about which model generated our collected data. \cite{DBLP:journals/corr/KendallG17}e.g. High when a model faces an image that isn't in any class(will mitigate given enough data)

\subsection{how to derive}
\subsubsection{MC sampling methods}
The MC samples are generally computed using an ensemble of neural networks. The prediction ensemble could either be generated by differently trained networks, or by keeping drop-out at test-time\cite{DBLP:journals/corr/abs-1907-06890}.
\paragraph{an example: MC dropout}
Yarin Gal et al. showed that a neural network with arbitrary depth and non-linearities, with dropout applied before every weight layer, is mathematically equivalent to an approximation to a well known Bayesian model(deep Gaussian process model)\cite{gal2015dropout}. Thus they can derive the uncertainty simply by collecting the results(mean for predictive mean and variance for uncertainty) of stochastic forward passes through the model.
\paragraph{pros and cons}
It is a practical approach for approximate inference in large and complex models because it does not requires more parameters and sometimes not even more time complexity. However, the dropout approximation fails in some network architectures\cite{gal2015bayesian}. Also, the prior are often fixed. For example, MC dropout can only works when the prior satisfies the assumption of bernoulli distribution.
\subsubsection{variational methods}
Bayesian Neural Network(BNN) automatically yield us the prediction uncertainties because it assumes that its weight parameters $w$ are random variables under certain distributions. Thus after we achieve the posterior $p(w|X,Y)$, where $X,Y$ are the given dataset, the uncertainty can be derived from the prediction $y$ which is based on a given $x$. Here $y$ is also a random variable. The variational inference way of training BNN is the process of pushing these distributions $q_\theta(w)$ to be as close as possible to the posterior $p(w|X,Y)$ and $\theta$ is the parameters of the distribution of $w$, which will be constant after training process. Through this process, it converts the inference problem into an optimization problem.
\paragraph{an example: Bayes by Backprop}
In one of the practical algorithms, Bayes by Backprop\cite{blundell2015weight}, they use back propagation just like normal NNs, but it is the parameters of $q_\theta(w)$, $\theta$, that are updated using reparamaterization trick and the loss derived from the objective function ELBO. ELBO is "evidence lower bound". By maximizing this we can get the $q_\theta(w)$ that is close to $p(w|X,Y)$.
\paragraph{pros and cons}
It optimises a well-defined objective function to learn a distribution on the weights of a neural network. However in practice, Bayesian NNs are often harder to implement and computationally slower to train compared to non-Bayesian NNs\cite{NIPS2017_7219}.
\section{aleatoric uncertainty}
\subsection{definition}
Aleatoric uncertainty captures noise inherent in the observations.\cite{DBLP:journals/corr/KendallG17} E.g. High when data has noise that cannot be explained by the real correlation of $X$ and $Y$(will not mitigate given data because new data also has this kind of noise)
We can use a single network to transform the input x, with its head split to predict both output y as well as aleatoric uncertainty. We can update the parameters with a specific loss to achieve intended function\cite{DBLP:journals/corr/KendallG17}.
\subsection{how to derive}
Kendall et al. proposed a way to learn how to yield aleatoric(data) uncertainty from the data itself. They feed the input $\bf{x}$ into one network, with its head split to predict both $\hat{\bf{y}}_i$ as well as the data uncertainty $\sigma_i$. The loss will be as below($D$ is the number of pixels in image segmentation task in the paper):
$$
    \mathcal{L}_{BNN}(\theta)=\frac{1}{D} \sum_{i} \frac{1}{2} \hat{\sigma}_{i}^{-2}\left\|\mathbf{y}_{i}-\hat{\mathbf{y}}_{i}\right\|^{2}+\frac{1}{2} \log \hat{\sigma}_{i}^{2}
$$
Here the parameters in the $\sigma_i$ end is not a random variable because we do not need uncertainty for uncertainty. The loss function, though derived from mathematical deduction, can be explained straightfowardly.
\nocite{*}
\bibliographystyle{unsrt}
\bibliography{lib}
\end{document}